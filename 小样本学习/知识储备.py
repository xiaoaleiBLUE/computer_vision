
"""
测试脚本
1. support set(参考集合) 每一类的图片输入特征提取网络获取 embedding
2. 计算这一类的平均值, 在归一化得到 u1, u2, u3
3. query(查询的图片) 输入预训练网络得到特征向量, 归一化, 然后与 u1, u2, u3 堆成矩阵 M 乘积得到余弦相似度
计算余弦相似度 cos t = a * b / |a| * |b|
监督学习的训练所需样本非常多,  预测的图片需要在 样本中

小样本: 训练的目的不在是识别照片, 学会事物之间的异同, 会区分不同的事物(理解事物之间的异同)
给定两张图片, 能告诉我们是不是一类东西(两张图片所属的类别也不在训练集中)

小样本学习基本思路:
大数据集训练相似度函数
提供 Support set
用 query 和 support set -- 对比相似度, 找出最高的作为结果

关键: 判断图片相似度的模型

Siamese Network 连体网络
Triplet loss (三元组损失)
1. 首先从数据集中随机选出 3 张图片, 选出熊猫一张图片, 即为 ( anchor ) 锚框
2. 同时在熊猫的那一类图片中选取一张图片, 即为 ( positive )  正样本
3. 选择袋鼠图片, 即为( negative ) 负样本
4. 把三张图片分别输入卷积神经网络, 得到 3 个特征向量,
5. 计算 正样本 特征向量 与 锚点 特征向量 欧式距离 的 平方  d+
6. 计算 负样本 特征向量 与 锚点 特征向量 欧式距离 的 平方  d—
相同类别聚在一起 d+ 要小一些, 不同距离要分开一些 d- 要大一些

超参数: margin(人为设置的)
如果 d- > d+ + margin(margin > 0), 理想状态, loss = 0
否则 loss = d+ + margin - d-
即  loss = max{0, d+ + margin - d-}

一个人会骑自行车, 骑摩托车更容易学了(一个人会英语, 法语更容易学了), 已有的经验 -- 解决相似的任务
特征提取 --> 全连接(分类)

迁移学习: 利用数据, 任务, 模型间的相似度, 将训练好的内容应用到新的任务上去

为什么使用 ?
缺数据: 训练集样本大小有限, 实际上很少有人会从头完整训练一个 CNN 网络模型(随机初始化参数)
节约训练时间: 使用迁移学习可以提前达到要求的准确度

2种类型:
预训练的 ConvNet: 作为 feature extractor(特征提取器)
Fine tune(微调) 预训练的 ConvNet
冻结特征提取模块, 替换 分类器

feature extractor(特征提取器):
1. 挑选一个预训练的卷积神经网络模型
2. 冻结特征提取模块
3. 更换分类器, 使得新的模型输出为自己需要的类别
4. 用新数据训练这个新的网络模型
5. Fine tune(微调): 后半部分进行解冻(微调)

学习率: 一般 fine-tune 时使用的学习率很小(1e-5), 否则可能过快地改变 pretrained model 参数, 导致模型失效
"""













